{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21368,
     "status": "ok",
     "timestamp": 1621771150280,
     "user": {
      "displayName": "汪玄同",
      "photoUrl": "",
      "userId": "02762474676861075463"
     },
     "user_tz": -480
    },
    "id": "qA9VkoAABReb",
    "outputId": "d7e74266-a531-4d03-bc87-db2beda2cadc"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# # import Google Drive 套件\n",
    "# from google.colab import drive\n",
    "# # 將自己的雲端硬碟掛載上去\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# os.chdir('./gdrive/MyDrive/Colab Notebooks/deep_learning/aoi')      # 檔案目錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1621771150281,
     "user": {
      "displayName": "汪玄同",
      "photoUrl": "",
      "userId": "02762474676861075463"
     },
     "user_tz": -480
    },
    "id": "gBPgmbridWod",
    "outputId": "1c7642b1-a2ac-40b2-89be-69c7d5109a45"
   },
   "outputs": [],
   "source": [
    "# os.listdir('./../../../../../'), os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 60354,
     "status": "ok",
     "timestamp": 1621771210632,
     "user": {
      "displayName": "汪玄同",
      "photoUrl": "",
      "userId": "02762474676861075463"
     },
     "user_tz": -480
    },
    "id": "uzoMGHW_csbk",
    "outputId": "4bf45207-7ad6-42f5-df2a-f7258851d393"
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.copyfile('./dataset.zip', './../../../../../dataset.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 45050,
     "status": "ok",
     "timestamp": 1621771255680,
     "user": {
      "displayName": "汪玄同",
      "photoUrl": "",
      "userId": "02762474676861075463"
     },
     "user_tz": -480
    },
    "id": "z6ActsHaevkw"
   },
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# def zip_list(file_path):\n",
    "#     zf = zipfile.ZipFile(file_path, 'r')\n",
    "#     zf.extractall('./../../../../../')\n",
    "\n",
    "# file_path = './../../../../../dataset.zip'\n",
    "# zip_list(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1621771255680,
     "user": {
      "displayName": "汪玄同",
      "photoUrl": "",
      "userId": "02762474676861075463"
     },
     "user_tz": -480
    },
    "id": "FpVUvSzMjE4r"
   },
   "outputs": [],
   "source": [
    "# os.remove('./../../../../../dataset.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1573,
     "status": "ok",
     "timestamp": 1621771297114,
     "user": {
      "displayName": "汪玄同",
      "photoUrl": "",
      "userId": "02762474676861075463"
     },
     "user_tz": -480
    },
    "id": "x02yHWzLn5HI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append('./GWFM/')\n",
    "\n",
    "import GWFM.methods.AlgOT as at\n",
    "import GWFM.methods.FusedGromovWassersteinFactorization as FW\n",
    "from methods.AlgOT import cost_mat, ot_fgw\n",
    "from methods.DataIO import StructuralDataSampler, StructuralDataSampler2, structural_data_split\n",
    "from sklearn.manifold import MDS, TSNE\n",
    "from typing import List, Tuple\n",
    "# import functions as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1621764550999,
     "user": {
      "displayName": "汪玄同",
      "photoUrl": "",
      "userId": "02762474676861075463"
     },
     "user_tz": -480
    },
    "id": "KC0U8S1iBITZ",
    "outputId": "82f804e1-6af0-4585-9155-882fd8a81976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 26 19:25:40 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100S-PCI...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   49C    P0    41W / 250W |  20959MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2041      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A      8034      C   /usr/bin/python3                  999MiB |\n",
      "|    0   N/A  N/A     27754      C   /usr/bin/python3                 9833MiB |\n",
      "|    0   N/A  N/A     35689      C   /usr/bin/python3                10117MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE-DiGsRBITa"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset/datas.pickle', 'rb') as f:\n",
    "    datas = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSave = './models/gwModel_atoms56.pt'\n",
    "# 訓練超參數 model\n",
    "data_sampler = StructuralDataSampler2(datas)\n",
    "num_samples = len(data_sampler)\n",
    "num_atoms = 56\n",
    "size_atoms = num_atoms * [35]\n",
    "ot_method = 'ppa'\n",
    "gamma = 5e-2\n",
    "gwb_layers = 5\n",
    "ot_layers = 30\n",
    "dim_embedding = 4\n",
    "num_classes = None       # 先驗分布\n",
    "prior = None             # 先驗分布\n",
    "\n",
    "# 訓練超參數 train\n",
    "size_batch = 16\n",
    "epochs = 10\n",
    "lr = 0.1\n",
    "weight_decay = 0\n",
    "shuffle_data = True\n",
    "zeta = 0.1  # the weight of diversity regularizer\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FW.FGWF(num_samples=num_samples,\n",
    "                num_classes=num_classes,\n",
    "                size_atoms=size_atoms,\n",
    "                dim_embedding=dim_embedding,\n",
    "                ot_method=ot_method,\n",
    "                gamma=gamma,\n",
    "                gwb_layers=gwb_layers,\n",
    "                ot_layers=ot_layers,\n",
    "                prior=prior)\n",
    "# model.load_state_dict(torch.load('./models/gwModel1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_FGWF(model,\n",
    "              data_sampler,\n",
    "              size_batch: int = 16,\n",
    "              epochs: int = 10,\n",
    "              lr: float = 1e-1,\n",
    "              weight_decay: float = 0,\n",
    "              shuffle_data: bool = True,\n",
    "              zeta: float = None,\n",
    "              device=None):\n",
    "    \"\"\"\n",
    "    training a FGWF model\n",
    "    Args:\n",
    "        model: a FGWF model\n",
    "        database: a list of data, each element is a list representing [cost, distriubtion, feature, label]\n",
    "        size_batch: the size of batch, deciding the frequency of backpropagation\n",
    "        epochs: the number epochs\n",
    "        lr: learning rate\n",
    "        weight_decay: the weight of the l2-norm regularization of parameters\n",
    "        shuffle_data: whether shuffle data in each epoch\n",
    "        zeta: the weight of the regularizer enhancing the diversity of atoms\n",
    "        mode: fit or transform\n",
    "        visualize_prefix: display learning result after each epoch or not\n",
    "    \"\"\"\n",
    "    global modelSave\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)  \n",
    "#     model.to(device)\n",
    "    model.train()\n",
    "\n",
    "#     data_sampler = StructuralDataSampler2(database)\n",
    "    num_samples = data_sampler.__len__()\n",
    "    index_samples = list(range(num_samples))\n",
    "    index_atoms = list(range(model.num_atoms))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('##############{}'.format(epoch))\n",
    "        counts = 0\n",
    "        t_start = time.time()\n",
    "        loss_total = 0\n",
    "        d_fgw_total = 0\n",
    "        reg_total = 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if shuffle_data:\n",
    "            random.shuffle(index_samples)\n",
    "\n",
    "        for idx in index_samples:\n",
    "            data = data_sampler.__getitem__(idx)\n",
    "#             graph = data[0].to(device)\n",
    "#             prob = data[1].to(device)\n",
    "#             emb = data[2].to(device)\n",
    "            graph = data[0]\n",
    "            prob = data[1]\n",
    "            emb = data[2]\n",
    "\n",
    "            # Envelop Theorem\n",
    "            # feed-forward computation of barycenter B({Ck}, w) and its transports {Trans_k}\n",
    "            trans = []\n",
    "            for k in range(model.num_atoms):\n",
    "                graph_k = model.output_atoms(k).data\n",
    "                emb_k = model.embeddings[k].data\n",
    "#                 psk = model.ps[k].to(device)\n",
    "                psk = model.ps[k]\n",
    "                _, tran_k = ot_fgw(graph_k, graph, psk, prob,\n",
    "                                   model.ot_method, model.gamma, model.ot_layers,\n",
    "                                   emb_k, emb)\n",
    "                trans.append(tran_k)\n",
    "            tran = torch.diag(prob[:, 0])\n",
    "\n",
    "            d_fgw, _, _, _ = model(graph, prob, emb, idx, trans, tran)\n",
    "            d_fgw_total += d_fgw\n",
    "            loss_total += d_fgw\n",
    "\n",
    "            if zeta is not None:\n",
    "                random.shuffle(index_atoms)\n",
    "                graph1 = model.output_atoms(index_atoms[0])\n",
    "                emb1 = model.embeddings[index_atoms[0]]\n",
    "#                 p1 = model.ps[index_atoms[0]].to(device)\n",
    "                p1 = model.ps[index_atoms[0]]\n",
    "\n",
    "                graph2 = model.output_atoms(index_atoms[1])\n",
    "                emb2 = model.embeddings[index_atoms[1]]\n",
    "#                 p2 = model.ps[index_atoms[1]].to(device)\n",
    "                p2 = model.ps[index_atoms[1]]\n",
    "                _, tran12 = ot_fgw(graph1.data, graph2.data, p1, p2,\n",
    "                                   model.ot_method, model.gamma, model.ot_layers,\n",
    "                                   emb1.data, emb2.data)\n",
    "                reg = FW.fgwd(graph1, emb1, p1, graph2, emb2, p2, tran12)\n",
    "\n",
    "                reg_total += zeta * reg\n",
    "                loss_total -= zeta * reg\n",
    "\n",
    "            counts += 1\n",
    "            if counts % size_batch == 0 or counts == num_samples:\n",
    "                if counts % size_batch == 0:\n",
    "                    num = size_batch\n",
    "                else:\n",
    "                    num = counts % size_batch\n",
    "                loss_total.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                print('-- {}/{} [{:.1f}%], loss={:.4f}, dgw={:.4f}, reg={:.4f}, time={:.2f}s.'.format(\n",
    "                    counts, num_samples, counts / num_samples * 100.0,\n",
    "                    loss_total / num, d_fgw_total / num, reg_total / num, time.time() - t_start))\n",
    "\n",
    "                t_start = time.time()\n",
    "                loss_total = 0\n",
    "                d_fgw_total = 0\n",
    "                reg_total = 0\n",
    "                optimizer.zero_grad()\n",
    "        torch.save(model.state_dict(), modelSave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############0\n",
      "-- 16/2000 [0.8%], loss=0.5265, dgw=0.5448, reg=0.0183, time=17.70s.\n",
      "-- 32/2000 [1.6%], loss=0.3617, dgw=0.3801, reg=0.0184, time=18.15s.\n",
      "-- 48/2000 [2.4%], loss=0.2692, dgw=0.2863, reg=0.0171, time=18.05s.\n",
      "-- 64/2000 [3.2%], loss=0.2268, dgw=0.2439, reg=0.0170, time=18.06s.\n",
      "-- 80/2000 [4.0%], loss=0.2046, dgw=0.2201, reg=0.0156, time=17.70s.\n",
      "-- 96/2000 [4.8%], loss=0.1819, dgw=0.1981, reg=0.0162, time=17.31s.\n",
      "-- 112/2000 [5.6%], loss=0.1847, dgw=0.2015, reg=0.0168, time=17.28s.\n",
      "-- 128/2000 [6.4%], loss=0.1642, dgw=0.1806, reg=0.0164, time=17.66s.\n",
      "-- 144/2000 [7.2%], loss=0.1645, dgw=0.1794, reg=0.0149, time=17.24s.\n",
      "-- 160/2000 [8.0%], loss=0.1480, dgw=0.1660, reg=0.0180, time=18.16s.\n",
      "-- 176/2000 [8.8%], loss=0.1397, dgw=0.1552, reg=0.0154, time=16.31s.\n",
      "-- 192/2000 [9.6%], loss=0.1315, dgw=0.1491, reg=0.0175, time=17.33s.\n",
      "-- 208/2000 [10.4%], loss=0.1330, dgw=0.1496, reg=0.0166, time=17.10s.\n",
      "-- 224/2000 [11.2%], loss=0.1207, dgw=0.1397, reg=0.0190, time=17.43s.\n",
      "-- 240/2000 [12.0%], loss=0.1277, dgw=0.1460, reg=0.0183, time=39.82s.\n",
      "-- 256/2000 [12.8%], loss=0.1211, dgw=0.1395, reg=0.0184, time=16.76s.\n",
      "-- 272/2000 [13.6%], loss=0.1050, dgw=0.1246, reg=0.0196, time=18.85s.\n",
      "-- 288/2000 [14.4%], loss=0.1373, dgw=0.1590, reg=0.0216, time=16.69s.\n",
      "-- 304/2000 [15.2%], loss=0.0979, dgw=0.1206, reg=0.0226, time=17.53s.\n",
      "-- 320/2000 [16.0%], loss=0.0922, dgw=0.1171, reg=0.0249, time=16.34s.\n",
      "-- 336/2000 [16.8%], loss=0.1021, dgw=0.1219, reg=0.0198, time=17.30s.\n",
      "-- 352/2000 [17.6%], loss=0.0896, dgw=0.1117, reg=0.0222, time=17.69s.\n",
      "-- 368/2000 [18.4%], loss=0.0927, dgw=0.1184, reg=0.0257, time=17.55s.\n",
      "-- 384/2000 [19.2%], loss=0.0916, dgw=0.1172, reg=0.0257, time=17.50s.\n",
      "-- 400/2000 [20.0%], loss=0.0858, dgw=0.1132, reg=0.0274, time=18.12s.\n",
      "-- 416/2000 [20.8%], loss=0.0895, dgw=0.1175, reg=0.0280, time=18.65s.\n",
      "-- 432/2000 [21.6%], loss=0.0722, dgw=0.1007, reg=0.0285, time=17.28s.\n",
      "-- 448/2000 [22.4%], loss=0.0894, dgw=0.1219, reg=0.0325, time=17.30s.\n",
      "-- 464/2000 [23.2%], loss=0.0753, dgw=0.1000, reg=0.0247, time=16.94s.\n",
      "-- 480/2000 [24.0%], loss=0.0897, dgw=0.1199, reg=0.0302, time=17.24s.\n",
      "-- 496/2000 [24.8%], loss=0.0888, dgw=0.1231, reg=0.0343, time=17.38s.\n",
      "-- 512/2000 [25.6%], loss=0.0694, dgw=0.0999, reg=0.0305, time=17.25s.\n",
      "-- 528/2000 [26.4%], loss=0.0642, dgw=0.0928, reg=0.0286, time=16.97s.\n",
      "-- 544/2000 [27.2%], loss=0.0821, dgw=0.1170, reg=0.0349, time=16.73s.\n",
      "-- 560/2000 [28.0%], loss=0.0743, dgw=0.1057, reg=0.0315, time=18.22s.\n",
      "-- 576/2000 [28.8%], loss=0.0640, dgw=0.0990, reg=0.0350, time=17.35s.\n",
      "-- 592/2000 [29.6%], loss=0.0663, dgw=0.0970, reg=0.0308, time=17.71s.\n",
      "-- 608/2000 [30.4%], loss=0.0656, dgw=0.1019, reg=0.0363, time=17.23s.\n",
      "-- 624/2000 [31.2%], loss=0.0764, dgw=0.1110, reg=0.0346, time=16.52s.\n",
      "-- 640/2000 [32.0%], loss=0.0513, dgw=0.0947, reg=0.0434, time=17.38s.\n",
      "-- 656/2000 [32.8%], loss=0.0761, dgw=0.1176, reg=0.0415, time=17.76s.\n",
      "-- 672/2000 [33.6%], loss=0.0782, dgw=0.1153, reg=0.0371, time=17.24s.\n",
      "-- 688/2000 [34.4%], loss=0.0655, dgw=0.1008, reg=0.0352, time=17.56s.\n",
      "-- 704/2000 [35.2%], loss=0.0553, dgw=0.0962, reg=0.0409, time=17.75s.\n",
      "-- 720/2000 [36.0%], loss=0.0631, dgw=0.0946, reg=0.0315, time=18.37s.\n",
      "-- 736/2000 [36.8%], loss=0.0604, dgw=0.0938, reg=0.0334, time=17.15s.\n",
      "-- 752/2000 [37.6%], loss=0.0525, dgw=0.0941, reg=0.0417, time=17.75s.\n",
      "-- 768/2000 [38.4%], loss=0.0792, dgw=0.1187, reg=0.0396, time=17.31s.\n",
      "-- 784/2000 [39.2%], loss=0.0599, dgw=0.0976, reg=0.0377, time=17.22s.\n",
      "-- 800/2000 [40.0%], loss=0.0445, dgw=0.0917, reg=0.0472, time=17.50s.\n",
      "-- 816/2000 [40.8%], loss=0.0558, dgw=0.0957, reg=0.0399, time=17.13s.\n",
      "-- 832/2000 [41.6%], loss=0.0415, dgw=0.0905, reg=0.0490, time=18.42s.\n",
      "-- 848/2000 [42.4%], loss=0.0535, dgw=0.0995, reg=0.0460, time=17.36s.\n",
      "-- 864/2000 [43.2%], loss=0.0513, dgw=0.0893, reg=0.0380, time=17.06s.\n",
      "-- 880/2000 [44.0%], loss=0.0618, dgw=0.1063, reg=0.0445, time=16.40s.\n",
      "-- 896/2000 [44.8%], loss=0.0506, dgw=0.0950, reg=0.0444, time=18.10s.\n",
      "-- 912/2000 [45.6%], loss=0.0420, dgw=0.0847, reg=0.0427, time=18.37s.\n",
      "-- 928/2000 [46.4%], loss=0.0359, dgw=0.0788, reg=0.0428, time=19.14s.\n",
      "-- 944/2000 [47.2%], loss=0.0366, dgw=0.0896, reg=0.0530, time=50.88s.\n",
      "-- 960/2000 [48.0%], loss=0.0343, dgw=0.0788, reg=0.0445, time=20.85s.\n",
      "-- 976/2000 [48.8%], loss=0.0433, dgw=0.0906, reg=0.0474, time=20.83s.\n",
      "-- 992/2000 [49.6%], loss=0.0477, dgw=0.0971, reg=0.0494, time=19.91s.\n",
      "-- 1008/2000 [50.4%], loss=0.0596, dgw=0.0996, reg=0.0401, time=17.43s.\n",
      "-- 1024/2000 [51.2%], loss=0.0385, dgw=0.0841, reg=0.0456, time=18.25s.\n",
      "-- 1040/2000 [52.0%], loss=0.0424, dgw=0.0855, reg=0.0431, time=18.46s.\n",
      "-- 1056/2000 [52.8%], loss=0.0328, dgw=0.0825, reg=0.0497, time=18.88s.\n",
      "-- 1072/2000 [53.6%], loss=0.0422, dgw=0.0897, reg=0.0475, time=18.54s.\n",
      "-- 1088/2000 [54.4%], loss=0.0617, dgw=0.1162, reg=0.0546, time=17.22s.\n",
      "-- 1104/2000 [55.2%], loss=0.0422, dgw=0.0988, reg=0.0567, time=17.27s.\n",
      "-- 1120/2000 [56.0%], loss=0.0480, dgw=0.0836, reg=0.0357, time=42.54s.\n",
      "-- 1136/2000 [56.8%], loss=0.0268, dgw=0.0855, reg=0.0588, time=17.55s.\n",
      "-- 1152/2000 [57.6%], loss=0.0372, dgw=0.0851, reg=0.0479, time=17.71s.\n",
      "-- 1168/2000 [58.4%], loss=0.0322, dgw=0.0796, reg=0.0475, time=17.95s.\n",
      "-- 1184/2000 [59.2%], loss=0.0318, dgw=0.0731, reg=0.0413, time=17.27s.\n",
      "-- 1200/2000 [60.0%], loss=0.0437, dgw=0.0805, reg=0.0368, time=18.75s.\n",
      "-- 1216/2000 [60.8%], loss=0.0367, dgw=0.0865, reg=0.0497, time=17.10s.\n",
      "-- 1232/2000 [61.6%], loss=0.0512, dgw=0.0891, reg=0.0379, time=17.11s.\n",
      "-- 1248/2000 [62.4%], loss=0.0213, dgw=0.0758, reg=0.0545, time=17.69s.\n",
      "-- 1264/2000 [63.2%], loss=0.0381, dgw=0.0770, reg=0.0389, time=18.17s.\n",
      "-- 1280/2000 [64.0%], loss=0.0343, dgw=0.0741, reg=0.0399, time=18.60s.\n",
      "-- 1296/2000 [64.8%], loss=0.0305, dgw=0.0774, reg=0.0469, time=17.24s.\n",
      "-- 1312/2000 [65.6%], loss=0.0268, dgw=0.0805, reg=0.0537, time=17.61s.\n",
      "-- 1328/2000 [66.4%], loss=0.0277, dgw=0.0764, reg=0.0487, time=18.10s.\n",
      "-- 1344/2000 [67.2%], loss=0.0347, dgw=0.0809, reg=0.0462, time=17.98s.\n",
      "-- 1360/2000 [68.0%], loss=0.0175, dgw=0.0723, reg=0.0548, time=17.47s.\n",
      "-- 1376/2000 [68.8%], loss=0.0254, dgw=0.0707, reg=0.0453, time=16.39s.\n",
      "-- 1392/2000 [69.6%], loss=0.0175, dgw=0.0657, reg=0.0482, time=18.08s.\n",
      "-- 1408/2000 [70.4%], loss=0.0338, dgw=0.0776, reg=0.0438, time=17.34s.\n",
      "-- 1424/2000 [71.2%], loss=0.0416, dgw=0.0889, reg=0.0472, time=17.18s.\n",
      "-- 1440/2000 [72.0%], loss=0.0278, dgw=0.0831, reg=0.0552, time=17.99s.\n",
      "-- 1456/2000 [72.8%], loss=0.0292, dgw=0.0730, reg=0.0439, time=16.53s.\n",
      "-- 1472/2000 [73.6%], loss=0.0297, dgw=0.0757, reg=0.0460, time=17.37s.\n",
      "-- 1488/2000 [74.4%], loss=0.0352, dgw=0.0798, reg=0.0446, time=17.03s.\n",
      "-- 1504/2000 [75.2%], loss=0.0250, dgw=0.0732, reg=0.0482, time=17.89s.\n",
      "-- 1520/2000 [76.0%], loss=0.0213, dgw=0.0753, reg=0.0540, time=16.86s.\n",
      "-- 1536/2000 [76.8%], loss=0.0311, dgw=0.0834, reg=0.0523, time=18.26s.\n",
      "-- 1552/2000 [77.6%], loss=0.0413, dgw=0.0926, reg=0.0513, time=16.85s.\n",
      "-- 1568/2000 [78.4%], loss=0.0305, dgw=0.0775, reg=0.0470, time=16.36s.\n",
      "-- 1584/2000 [79.2%], loss=0.0303, dgw=0.0709, reg=0.0406, time=17.53s.\n",
      "-- 1600/2000 [80.0%], loss=0.0333, dgw=0.0822, reg=0.0489, time=18.02s.\n",
      "-- 1616/2000 [80.8%], loss=0.0269, dgw=0.0741, reg=0.0472, time=17.77s.\n",
      "-- 1632/2000 [81.6%], loss=0.0093, dgw=0.0662, reg=0.0570, time=17.60s.\n",
      "-- 1648/2000 [82.4%], loss=0.0231, dgw=0.0717, reg=0.0486, time=17.99s.\n",
      "-- 1664/2000 [83.2%], loss=0.0178, dgw=0.0704, reg=0.0527, time=17.25s.\n",
      "-- 1680/2000 [84.0%], loss=0.0149, dgw=0.0734, reg=0.0585, time=16.85s.\n",
      "-- 1696/2000 [84.8%], loss=0.0314, dgw=0.0853, reg=0.0538, time=17.58s.\n",
      "-- 1712/2000 [85.6%], loss=0.0204, dgw=0.0725, reg=0.0521, time=18.15s.\n",
      "-- 1728/2000 [86.4%], loss=0.0273, dgw=0.0776, reg=0.0503, time=17.55s.\n",
      "-- 1744/2000 [87.2%], loss=0.0259, dgw=0.0733, reg=0.0474, time=17.42s.\n",
      "-- 1760/2000 [88.0%], loss=0.0203, dgw=0.0709, reg=0.0505, time=18.15s.\n",
      "-- 1776/2000 [88.8%], loss=0.0138, dgw=0.0682, reg=0.0545, time=18.12s.\n",
      "-- 1792/2000 [89.6%], loss=0.0147, dgw=0.0677, reg=0.0530, time=17.78s.\n",
      "-- 1808/2000 [90.4%], loss=0.0169, dgw=0.0679, reg=0.0510, time=17.57s.\n",
      "-- 1824/2000 [91.2%], loss=0.0329, dgw=0.0764, reg=0.0435, time=18.05s.\n",
      "-- 1840/2000 [92.0%], loss=0.0357, dgw=0.0856, reg=0.0499, time=17.53s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 1856/2000 [92.8%], loss=0.0235, dgw=0.0704, reg=0.0469, time=17.26s.\n",
      "-- 1872/2000 [93.6%], loss=0.0250, dgw=0.0735, reg=0.0485, time=17.18s.\n",
      "-- 1888/2000 [94.4%], loss=0.0286, dgw=0.0789, reg=0.0504, time=17.95s.\n",
      "-- 1904/2000 [95.2%], loss=0.0395, dgw=0.0977, reg=0.0582, time=17.76s.\n",
      "-- 1920/2000 [96.0%], loss=0.0287, dgw=0.0787, reg=0.0500, time=18.81s.\n",
      "-- 1936/2000 [96.8%], loss=0.0120, dgw=0.0673, reg=0.0552, time=16.81s.\n",
      "-- 1952/2000 [97.6%], loss=0.0277, dgw=0.0801, reg=0.0524, time=17.89s.\n",
      "-- 1968/2000 [98.4%], loss=0.0301, dgw=0.0776, reg=0.0475, time=18.36s.\n",
      "-- 1984/2000 [99.2%], loss=0.0190, dgw=0.0742, reg=0.0551, time=16.33s.\n",
      "-- 2000/2000 [100.0%], loss=0.0093, dgw=0.0652, reg=0.0559, time=16.79s.\n",
      "##############1\n",
      "-- 16/2000 [0.8%], loss=0.0290, dgw=0.0819, reg=0.0529, time=17.57s.\n",
      "-- 32/2000 [1.6%], loss=0.0300, dgw=0.0786, reg=0.0486, time=17.69s.\n",
      "-- 48/2000 [2.4%], loss=0.0253, dgw=0.0798, reg=0.0544, time=17.72s.\n",
      "-- 64/2000 [3.2%], loss=0.0301, dgw=0.0877, reg=0.0576, time=16.85s.\n",
      "-- 80/2000 [4.0%], loss=0.0149, dgw=0.0675, reg=0.0526, time=18.31s.\n",
      "-- 96/2000 [4.8%], loss=0.0310, dgw=0.0823, reg=0.0513, time=17.31s.\n",
      "-- 112/2000 [5.6%], loss=0.0207, dgw=0.0719, reg=0.0512, time=17.86s.\n",
      "-- 128/2000 [6.4%], loss=0.0166, dgw=0.0705, reg=0.0539, time=17.19s.\n",
      "-- 144/2000 [7.2%], loss=0.0112, dgw=0.0702, reg=0.0589, time=18.25s.\n",
      "-- 160/2000 [8.0%], loss=0.0164, dgw=0.0753, reg=0.0589, time=17.86s.\n",
      "-- 176/2000 [8.8%], loss=0.0330, dgw=0.0888, reg=0.0558, time=17.75s.\n",
      "-- 192/2000 [9.6%], loss=0.0184, dgw=0.0690, reg=0.0507, time=17.59s.\n",
      "-- 208/2000 [10.4%], loss=0.0160, dgw=0.0709, reg=0.0549, time=17.37s.\n",
      "-- 224/2000 [11.2%], loss=0.0274, dgw=0.0751, reg=0.0477, time=17.73s.\n",
      "-- 240/2000 [12.0%], loss=0.0052, dgw=0.0656, reg=0.0604, time=17.10s.\n",
      "-- 256/2000 [12.8%], loss=0.0273, dgw=0.0792, reg=0.0519, time=18.95s.\n",
      "-- 272/2000 [13.6%], loss=0.0129, dgw=0.0675, reg=0.0546, time=17.64s.\n"
     ]
    }
   ],
   "source": [
    "train_FGWF(model=model,\n",
    "           data_sampler=data_sampler,\n",
    "           size_batch=size_batch,\n",
    "           epochs=epochs,\n",
    "           lr=lr,\n",
    "           weight_decay=weight_decay,\n",
    "           shuffle_data=shuffle_data,\n",
    "           zeta=zeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.2516e+00, -1.4422e-01,  7.3147e+00,  2.0932e-01],\n",
       "        [ 2.1110e+00, -4.5244e-02,  4.1991e+00,  1.3844e+00],\n",
       "        [ 1.5844e+00,  1.5836e-01,  6.2744e+00, -1.4201e-01],\n",
       "        [ 2.5008e+00, -1.1238e-02,  5.7336e+00,  7.2038e-01],\n",
       "        [ 3.0396e+00,  3.7331e-01,  3.0778e+00, -8.5082e-01],\n",
       "        [ 2.5251e+00,  1.0760e-01,  4.9875e+00,  1.2279e+00],\n",
       "        [ 2.8257e+00, -1.3698e-01,  5.2744e+00, -6.7382e-01],\n",
       "        [ 1.6175e+00,  1.1862e-01,  5.3930e+00,  1.5521e+00],\n",
       "        [ 3.3539e+00,  2.2564e-01,  6.2408e+00,  1.9255e+00],\n",
       "        [ 3.0602e+00,  1.3467e-01,  2.8040e+00, -1.2654e+00],\n",
       "        [ 5.5106e+00, -1.6004e-02,  1.4879e+00,  1.5089e-01],\n",
       "        [ 2.4532e+00,  2.5648e-02,  4.4223e+00,  1.6875e+00],\n",
       "        [ 1.7086e+00, -4.1522e-02,  5.2322e+00, -5.5545e-01],\n",
       "        [ 2.7927e+00, -3.2976e-01,  5.0586e+00,  1.3816e+00],\n",
       "        [ 2.3055e+00, -3.0619e-01,  4.8395e+00,  1.2780e+00],\n",
       "        [ 2.5134e+00, -1.8995e-01,  5.0064e+00,  1.6160e+00],\n",
       "        [ 1.8454e+00,  1.2835e-01,  4.6726e+00, -1.1282e+00],\n",
       "        [ 3.1263e+00, -2.3132e-01,  2.4997e+00,  1.9386e+00],\n",
       "        [ 2.5899e+00, -9.8663e-02,  4.1074e+00, -1.8969e+00],\n",
       "        [ 7.8945e-01, -8.0670e-02,  6.2477e+00, -5.2961e-01],\n",
       "        [ 1.2372e+00, -1.3253e-01,  5.9088e+00, -1.3712e+00],\n",
       "        [-9.8990e-01, -3.9373e-01,  4.3699e+00,  1.1632e+00],\n",
       "        [ 3.3334e+00,  8.6859e-02,  2.9353e+00, -1.6630e+00],\n",
       "        [ 4.4646e+00,  8.6964e-01,  1.8416e+00,  1.4012e+00],\n",
       "        [ 1.9461e+00, -4.1491e-02,  7.3177e+00, -2.9699e-02],\n",
       "        [ 1.6674e+00, -1.8941e-01,  7.0681e+00, -2.0877e-01],\n",
       "        [ 2.0016e+00, -1.5608e-01,  4.9535e+00,  1.3199e+00],\n",
       "        [ 2.9510e+00,  1.7701e-01,  4.8181e+00, -6.6007e-01],\n",
       "        [ 1.9100e+00, -1.2498e-01,  6.2629e+00, -9.6650e-01],\n",
       "        [ 1.6563e+00, -4.5188e-02,  6.2596e+00, -2.2249e-01],\n",
       "        [ 1.9789e+00,  1.7414e-01,  7.2307e+00,  1.7250e-01],\n",
       "        [ 4.4972e+00,  3.1278e-01,  2.1065e+00, -1.6013e+00],\n",
       "        [ 5.4424e+00,  1.3891e-01,  2.4360e+00, -1.9337e+00],\n",
       "        [ 3.0092e+00, -4.0933e-03,  3.5652e+00, -6.1003e-01],\n",
       "        [ 4.0183e+00, -1.4093e-01,  1.7546e+00, -1.7681e-01]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  9.77670002, -3.54900002],\n",
       "       [ 1.        ,  0.        ,  8.91069984, -3.04900002],\n",
       "       [ 1.        ,  0.        ,  8.91069984, -2.04900002],\n",
       "       [ 1.        ,  0.        ,  9.77670002, -1.54900002],\n",
       "       [ 1.        ,  0.        , 10.6427002 , -2.04900002],\n",
       "       [ 1.        ,  0.        , 10.6427002 , -3.04900002],\n",
       "       [ 2.        ,  0.        ,  9.77670002, -0.54900002],\n",
       "       [ 1.        ,  0.        , 10.6427002 , -0.049     ],\n",
       "       [ 1.        ,  0.        , 11.50879955, -0.54900002],\n",
       "       [ 1.        ,  0.        , 11.50879955, -1.54900002],\n",
       "       [ 2.        ,  0.        , 10.6427002 ,  0.95099998],\n",
       "       [ 2.        ,  0.        ,  8.04469967, -3.54900002],\n",
       "       [ 1.        ,  0.        ,  7.17859983, -3.04900002],\n",
       "       [ 1.        ,  0.        ,  7.17859983, -2.04900002],\n",
       "       [ 1.        ,  0.        ,  8.04469967, -1.54900002],\n",
       "       [ 1.        ,  0.        ,  7.17859983,  0.95099998],\n",
       "       [ 1.        ,  0.        ,  8.94069958,  0.0416    ],\n",
       "       [ 1.        ,  0.        ,  9.27939987,  0.98250002],\n",
       "       [ 1.        ,  0.        ,  7.51739979,  1.89189994],\n",
       "       [ 1.        ,  0.        ,  4.94320011,  1.00440001],\n",
       "       [ 2.        ,  0.        ,  5.36899996,  0.0995    ],\n",
       "       [ 1.        ,  0.        ,  6.86549997,  2.93269992],\n",
       "       [ 2.        ,  0.        ,  4.00229979,  1.34319997],\n",
       "       [ 1.        ,  0.        ,  7.17859983, -0.049     ],\n",
       "       [ 2.        ,  0.        ,  8.04469967, -0.54900002],\n",
       "       [ 2.        ,  0.        ,  6.41139984, -0.6904    ],\n",
       "       [ 1.        ,  0.        ,  6.67859983, -3.91499996],\n",
       "       [ 1.        ,  0.        ,  6.17859983, -3.04900002],\n",
       "       [ 1.        ,  0.        ,  4.72809982, -1.12880003],\n",
       "       [ 1.        ,  0.        ,  6.39669991, -0.0576    ],\n",
       "       [ 1.        ,  0.        ,  5.7512002 ,  0.7062    ],\n",
       "       [ 1.        ,  0.        ,  4.08260012, -0.3651    ],\n",
       "       [ 1.        ,  0.        ,  3.56419992, -3.0381999 ],\n",
       "       [ 2.        ,  0.        ,  4.56080008, -3.12190008],\n",
       "       [ 1.        ,  0.        ,  2.85529995, -0.4091    ],\n",
       "       [ 2.        ,  0.        ,  2.80040002, -3.68359995],\n",
       "       [ 1.        ,  0.        ,  5.37349987, -1.89260006],\n",
       "       [ 2.        ,  0.        ,  6.31260014, -1.54900002],\n",
       "       [ 2.        ,  0.        ,  5.20160007, -2.87779999],\n",
       "       [ 1.        ,  0.        ,  2.09829998,  0.24429999],\n",
       "       [ 1.        ,  0.        ,  2.        , -0.92699999],\n",
       "       [ 1.        ,  0.        ,  7.05289984,  3.91499996],\n",
       "       [ 1.        ,  0.        ,  5.98920012,  3.4145    ],\n",
       "       [ 1.        ,  0.        ,  7.85610008,  2.83279991],\n",
       "       [ 1.        ,  0.        ,  3.43709993,  0.3987    ],\n",
       "       [ 2.        ,  0.        , 12.37479973, -0.049     ],\n",
       "       [ 1.        ,  0.        , 13.2407999 , -0.54900002]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas[0]['nodesAttribute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = torch.tensor(datas[0]['adjecentMatrix'], dtype=torch.float)\n",
    "ct = torch.tensor(datas[1]['adjecentMatrix'], dtype=torch.float)\n",
    "embs = torch.tensor(datas[0]['nodesAttribute'], dtype=torch.float)\n",
    "embt = torch.tensor(datas[1]['nodesAttribute'], dtype=torch.float)\n",
    "ps = torch.ones(cs.shape[0], 1, dtype=torch.float) / cs.shape[0]\n",
    "pt = torch.ones(ct.shape[0], 1, dtype=torch.float) / ct.shape[0]\n",
    "tran = torch.matmul(ps, pt.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs1 = at.ot_fgw(cs, ct, ps, pt, 'b-admm', 1., 10, embs, embt)     # 計算兩圖的距離\n",
    "outputs2 = at.ot_fgw(cs, ct, ps, pt, 'b-admm', 1., 10)     # 計算兩圖的距離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2803),\n",
       " tensor([[0.0019, 0.0029, 0.0022, 0.0020, 0.0013, 0.0017, 0.0035, 0.0021, 0.0013,\n",
       "          0.0012, 0.0013],\n",
       "         [0.0019, 0.0032, 0.0022, 0.0021, 0.0015, 0.0018, 0.0031, 0.0020, 0.0012,\n",
       "          0.0012, 0.0012],\n",
       "         [0.0017, 0.0026, 0.0021, 0.0023, 0.0018, 0.0020, 0.0025, 0.0022, 0.0014,\n",
       "          0.0015, 0.0013],\n",
       "         [0.0015, 0.0024, 0.0019, 0.0024, 0.0020, 0.0021, 0.0021, 0.0023, 0.0015,\n",
       "          0.0017, 0.0013],\n",
       "         [0.0016, 0.0025, 0.0020, 0.0024, 0.0019, 0.0020, 0.0023, 0.0023, 0.0014,\n",
       "          0.0016, 0.0013],\n",
       "         [0.0017, 0.0027, 0.0021, 0.0021, 0.0015, 0.0018, 0.0030, 0.0023, 0.0014,\n",
       "          0.0015, 0.0013],\n",
       "         [0.0017, 0.0016, 0.0019, 0.0020, 0.0017, 0.0020, 0.0017, 0.0025, 0.0021,\n",
       "          0.0021, 0.0019],\n",
       "         [0.0013, 0.0018, 0.0016, 0.0025, 0.0024, 0.0023, 0.0014, 0.0025, 0.0018,\n",
       "          0.0024, 0.0014],\n",
       "         [0.0013, 0.0019, 0.0017, 0.0025, 0.0023, 0.0023, 0.0015, 0.0024, 0.0017,\n",
       "          0.0022, 0.0014],\n",
       "         [0.0015, 0.0021, 0.0018, 0.0023, 0.0018, 0.0020, 0.0021, 0.0025, 0.0017,\n",
       "          0.0020, 0.0014],\n",
       "         [0.0014, 0.0012, 0.0016, 0.0018, 0.0017, 0.0019, 0.0012, 0.0027, 0.0026,\n",
       "          0.0030, 0.0022],\n",
       "         [0.0025, 0.0026, 0.0026, 0.0015, 0.0010, 0.0014, 0.0039, 0.0018, 0.0013,\n",
       "          0.0009, 0.0016],\n",
       "         [0.0020, 0.0039, 0.0023, 0.0020, 0.0014, 0.0017, 0.0033, 0.0016, 0.0010,\n",
       "          0.0009, 0.0011],\n",
       "         [0.0019, 0.0029, 0.0022, 0.0021, 0.0016, 0.0019, 0.0028, 0.0020, 0.0013,\n",
       "          0.0013, 0.0013],\n",
       "         [0.0017, 0.0025, 0.0020, 0.0023, 0.0019, 0.0020, 0.0022, 0.0022, 0.0015,\n",
       "          0.0016, 0.0014],\n",
       "         [0.0012, 0.0013, 0.0014, 0.0025, 0.0030, 0.0025, 0.0008, 0.0022, 0.0020,\n",
       "          0.0027, 0.0016],\n",
       "         [0.0013, 0.0015, 0.0016, 0.0022, 0.0021, 0.0022, 0.0014, 0.0026, 0.0020,\n",
       "          0.0026, 0.0017],\n",
       "         [0.0011, 0.0013, 0.0014, 0.0022, 0.0022, 0.0022, 0.0011, 0.0027, 0.0023,\n",
       "          0.0031, 0.0017],\n",
       "         [0.0010, 0.0009, 0.0012, 0.0024, 0.0034, 0.0025, 0.0006, 0.0022, 0.0023,\n",
       "          0.0033, 0.0017],\n",
       "         [0.0012, 0.0010, 0.0014, 0.0021, 0.0025, 0.0024, 0.0007, 0.0023, 0.0026,\n",
       "          0.0031, 0.0020],\n",
       "         [0.0021, 0.0011, 0.0020, 0.0016, 0.0016, 0.0018, 0.0013, 0.0022, 0.0027,\n",
       "          0.0021, 0.0028],\n",
       "         [0.0008, 0.0006, 0.0009, 0.0021, 0.0035, 0.0024, 0.0004, 0.0021, 0.0026,\n",
       "          0.0040, 0.0019],\n",
       "         [0.0017, 0.0005, 0.0015, 0.0011, 0.0012, 0.0014, 0.0006, 0.0020, 0.0041,\n",
       "          0.0030, 0.0041],\n",
       "         [0.0014, 0.0017, 0.0017, 0.0023, 0.0023, 0.0023, 0.0014, 0.0024, 0.0019,\n",
       "          0.0023, 0.0016],\n",
       "         [0.0019, 0.0016, 0.0020, 0.0019, 0.0016, 0.0019, 0.0017, 0.0024, 0.0022,\n",
       "          0.0020, 0.0021],\n",
       "         [0.0021, 0.0014, 0.0022, 0.0016, 0.0013, 0.0016, 0.0020, 0.0024, 0.0024,\n",
       "          0.0019, 0.0025],\n",
       "         [0.0023, 0.0029, 0.0024, 0.0014, 0.0008, 0.0012, 0.0051, 0.0018, 0.0011,\n",
       "          0.0008, 0.0014],\n",
       "         [0.0022, 0.0027, 0.0024, 0.0015, 0.0009, 0.0013, 0.0045, 0.0020, 0.0013,\n",
       "          0.0010, 0.0015],\n",
       "         [0.0020, 0.0028, 0.0022, 0.0021, 0.0018, 0.0020, 0.0023, 0.0018, 0.0014,\n",
       "          0.0012, 0.0015],\n",
       "         [0.0015, 0.0016, 0.0018, 0.0021, 0.0019, 0.0021, 0.0015, 0.0026, 0.0021,\n",
       "          0.0024, 0.0018],\n",
       "         [0.0013, 0.0012, 0.0015, 0.0020, 0.0020, 0.0021, 0.0010, 0.0026, 0.0025,\n",
       "          0.0030, 0.0020],\n",
       "         [0.0019, 0.0021, 0.0020, 0.0022, 0.0021, 0.0022, 0.0016, 0.0020, 0.0018,\n",
       "          0.0016, 0.0017],\n",
       "         [0.0028, 0.0039, 0.0025, 0.0012, 0.0007, 0.0011, 0.0054, 0.0011, 0.0008,\n",
       "          0.0004, 0.0013],\n",
       "         [0.0035, 0.0025, 0.0029, 0.0010, 0.0006, 0.0010, 0.0047, 0.0013, 0.0012,\n",
       "          0.0005, 0.0019],\n",
       "         [0.0023, 0.0021, 0.0023, 0.0019, 0.0018, 0.0021, 0.0018, 0.0018, 0.0019,\n",
       "          0.0013, 0.0021],\n",
       "         [0.0044, 0.0020, 0.0029, 0.0006, 0.0003, 0.0006, 0.0064, 0.0008, 0.0010,\n",
       "          0.0003, 0.0022],\n",
       "         [0.0021, 0.0031, 0.0023, 0.0019, 0.0014, 0.0018, 0.0031, 0.0019, 0.0013,\n",
       "          0.0011, 0.0014],\n",
       "         [0.0025, 0.0020, 0.0025, 0.0016, 0.0012, 0.0016, 0.0026, 0.0020, 0.0019,\n",
       "          0.0013, 0.0021],\n",
       "         [0.0031, 0.0022, 0.0027, 0.0011, 0.0007, 0.0011, 0.0044, 0.0016, 0.0015,\n",
       "          0.0008, 0.0021],\n",
       "         [0.0022, 0.0008, 0.0020, 0.0012, 0.0011, 0.0015, 0.0011, 0.0021, 0.0034,\n",
       "          0.0022, 0.0037],\n",
       "         [0.0034, 0.0017, 0.0028, 0.0010, 0.0007, 0.0011, 0.0036, 0.0016, 0.0018,\n",
       "          0.0008, 0.0027],\n",
       "         [0.0008, 0.0005, 0.0009, 0.0015, 0.0019, 0.0018, 0.0003, 0.0024, 0.0035,\n",
       "          0.0055, 0.0024],\n",
       "         [0.0008, 0.0004, 0.0009, 0.0014, 0.0018, 0.0017, 0.0003, 0.0024, 0.0036,\n",
       "          0.0054, 0.0025],\n",
       "         [0.0009, 0.0007, 0.0011, 0.0017, 0.0019, 0.0019, 0.0006, 0.0027, 0.0030,\n",
       "          0.0046, 0.0021],\n",
       "         [0.0016, 0.0010, 0.0017, 0.0016, 0.0015, 0.0018, 0.0011, 0.0025, 0.0030,\n",
       "          0.0028, 0.0027],\n",
       "         [0.0015, 0.0015, 0.0018, 0.0021, 0.0019, 0.0020, 0.0015, 0.0026, 0.0021,\n",
       "          0.0024, 0.0018],\n",
       "         [0.0013, 0.0017, 0.0016, 0.0021, 0.0017, 0.0020, 0.0018, 0.0028, 0.0020,\n",
       "          0.0026, 0.0016]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "R6RBU0SYBITh"
   ],
   "name": "train_module.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
